{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader.data as web\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing;\n",
    "from sklearn.model_selection import cross_validate as cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "forecast_out = 365 #Days from now\n",
    "\n",
    "stock_ticker ='JPM'\n",
    "stock_parameter ='Low'\n",
    "epoch_number=50\n",
    "epoch_number_forecast=50\n",
    "\n",
    "end = datetime.datetime.now()#-timedelta(7) #remove timedetla -1 to go to productions mode\n",
    "start = datetime.datetime.now()-timedelta(forecast_out)\n",
    "\n",
    "# benchmark = web.DataReader(stock_ticker, 'yahoo', start, end )\n",
    "stock = web.DataReader(stock_ticker, 'yahoo', start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=20\n",
    "test_index = len(stock[stock_parameter])- test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = stock[stock_parameter].iloc[:test_index]\n",
    "test= stock[stock_parameter].iloc[test_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "scaler.fit(train.to_frame())\n",
    "scaled_train = scaler.transform(train.to_frame())\n",
    "scaled_test = scaler.transform(test.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=test_size-1\n",
    "generator = TimeseriesGenerator(scaled_train,scaled_train, length=length, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features =1\n",
    "model= Sequential()\n",
    "# pretty good model at 200 epochs\n",
    "# model.add(LSTM(50, activation='relu', input_shape=(length, n_features)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(25, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(100, activation='relu', input_shape=(length, n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator= TimeseriesGenerator(scaled_test, scaled_test,\n",
    "                                          length=length, batch_size =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# model.fit_generator(generator, epochs=20,\n",
    "#                    validation_data=validation_generator, callbacks=[early_stop])\n",
    "model.fit_generator(generator, epochs=epoch_number,\n",
    "                   validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses= pd.DataFrame(model.history.history)\n",
    "ax =losses.plot()\n",
    "plt.show()\n",
    "plt.savefig(stock_ticker+'_'+stock_parameter+'loss_chart.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions =[]\n",
    "first_eval_batch = scaled_train[-length:]\n",
    "current_batch = first_eval_batch.reshape((1, length, n_features))\n",
    "for i in range(len(test)):\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    test_predictions.append(current_pred)\n",
    "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions =scaler.inverse_transform(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(test)\n",
    "predictions['Predictions'] = true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=predictions.plot(figsize=(12,8))\n",
    "plt.show()\n",
    "plt.savefig(stock_ticker+'_'+stock_parameter+'predictions_chart.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save(stock_ticker+'_'+stock_parameter+'prediction'+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scaler = MinMaxScaler()\n",
    "scaled_full_data = full_scaler.fit_transform(stock[stock_parameter].to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=19\n",
    "generator=TimeseriesGenerator(scaled_full_data, scaled_full_data, length=length, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_model= Sequential()\n",
    "forecast_model.add(LSTM(100, activation='relu', input_shape=(length, n_features)))\n",
    "forecast_model.add(Dropout(0.2))\n",
    "forecast_model.add(Dense(50, activation='relu'))\n",
    "forecast_model.add(Dropout(0.2))\n",
    "forecast_model.add(Dense(15, activation='relu'))\n",
    "forecast_model.add(Dropout(0.2))\n",
    "forecast_model.add(Dense(1, activation='relu'))\n",
    "forecast_model.compile(optimizer='adam', loss='mse')\n",
    "forecast_model.fit_generator(generator, epochs=epoch_number_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save(stock_ticker+'_'+stock_parameter+'forecast'+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast =[]\n",
    "\n",
    "periods=19\n",
    "\n",
    "first_eval_batch = scaled_full_data[-length:]\n",
    "current_batch = first_eval_batch.reshape((1, length, n_features))\n",
    "\n",
    "for i in range(periods):\n",
    "    \n",
    "    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    \n",
    "    # store prediction\n",
    "    forecast.append(current_pred) \n",
    "    \n",
    "    # update batch to now include prediction and drop first value\n",
    "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = scaler.inverse_transform(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "forecast_index = pd.date_range(start=date.today(), periods = periods, freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = pd.DataFrame(data = forecast, index=forecast_index, columns=['Forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=stock[stock_parameter].plot()\n",
    "forecast_df.plot(ax=ax)\n",
    "plt.xlim( datetime.datetime.now()-timedelta(periods), datetime.datetime.now())\n",
    "plt.savefig(stock_ticker+'_'+stock_parameter+'forecast_chart.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo \n",
    "# add save charts \n",
    "# add save forecast.csv\n",
    "forecast_df.to_csv('forecast_'+stock_ticker+'_'+stock_parameter+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-python",
   "language": "python",
   "name": "gpu-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
